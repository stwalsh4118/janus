# [4-3] Implement Speech Synthesis integration

[Back to task list](./tasks.md)

## Description

Integrate Web Speech API's Speech Synthesis for automatic text-to-speech playback of responses. Create a custom hook that handles voice selection, rate/pitch control, interruption, and playback state management.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-10-12 00:00:00 | Created | N/A | Proposed | Task file created | Sean |
| 2025-10-13 12:00:00 | Status Update | Proposed | Agreed | Task approved, ready to implement speech synthesis | Sean |
| 2025-10-13 12:01:00 | Status Update | Agreed | InProgress | Starting implementation of useSpeechSynthesis hook | AI_Agent |
| 2025-10-13 12:15:00 | Status Update | InProgress | Review | Implementation complete: hook created, integrated into page.tsx with auto-play and stop functionality, TypeScript compiles without errors | AI_Agent |
| 2025-10-14 10:30:00 | Status Update | Review | Done | Replaced browser TTS with Kokoro-82M server-side TTS, added auto-detect with browser fallback, fixed race conditions and timeout handling, added debug text input | Sean |

## Requirements

**Current State:** Responses are displayed as text only. No audio playback.

1. Create `useSpeechSynthesis` hook:
   - Initialize speech synthesis
   - Handle voice selection (prefer natural voices)
   - Configure rate and pitch for driving context
   - Support interruption (stop speaking on tap)
   - Track speaking state

2. Auto-play responses:
   - Start speaking immediately when response received
   - Provide visual feedback during playback
   - Allow user to stop mid-sentence

3. Handle edge cases:
   - Browser not supported
   - No voices available
   - Very long responses (chunk if needed)
   - Queue management for multiple responses

## Implementation Plan

### 1. Create useSpeechSynthesis Hook
```typescript
// web/hooks/useSpeechSynthesis.ts
import { useState, useEffect, useCallback, useRef } from 'react';

const RATE = 1.0; // Normal speed
const PITCH = 1.0; // Normal pitch
const VOLUME = 1.0; // Full volume

interface UseSpeechSynthesisReturn {
  isSupported: boolean;
  isSpeaking: boolean;
  speak: (text: string) => void;
  stop: () => void;
  pause: () => void;
  resume: () => void;
}

export function useSpeechSynthesis(): UseSpeechSynthesisReturn {
  const [isSupported, setIsSupported] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [voices, setVoices] = useState<SpeechSynthesisVoice[]>([]);
  
  const synthRef = useRef<SpeechSynthesis | null>(null);

  useEffect(() => {
    if (typeof window !== 'undefined' && window.speechSynthesis) {
      setIsSupported(true);
      synthRef.current = window.speechSynthesis;

      // Load voices
      const loadVoices = () => {
        const availableVoices = window.speechSynthesis.getVoices();
        setVoices(availableVoices);
      };

      loadVoices();
      
      // Some browsers load voices asynchronously
      if (window.speechSynthesis.onvoiceschanged !== undefined) {
        window.speechSynthesis.onvoiceschanged = loadVoices;
      }
    }

    return () => {
      if (synthRef.current) {
        synthRef.current.cancel();
      }
    };
  }, []);

  const speak = useCallback((text: string) => {
    if (!synthRef.current || !text) return;

    // Cancel any ongoing speech
    synthRef.current.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    
    // Select best voice (prefer en-US, natural if available)
    const preferredVoice = voices.find(
      voice => voice.lang === 'en-US' && voice.localService
    ) || voices.find(
      voice => voice.lang.startsWith('en')
    ) || voices[0];

    if (preferredVoice) {
      utterance.voice = preferredVoice;
    }

    utterance.rate = RATE;
    utterance.pitch = PITCH;
    utterance.volume = VOLUME;
    utterance.lang = 'en-US';

    utterance.onstart = () => {
      setIsSpeaking(true);
    };

    utterance.onend = () => {
      setIsSpeaking(false);
    };

    utterance.onerror = (event) => {
      console.error('Speech synthesis error:', event);
      setIsSpeaking(false);
    };

    synthRef.current.speak(utterance);
  }, [voices]);

  const stop = useCallback(() => {
    if (synthRef.current) {
      synthRef.current.cancel();
      setIsSpeaking(false);
    }
  }, []);

  const pause = useCallback(() => {
    if (synthRef.current && synthRef.current.speaking) {
      synthRef.current.pause();
    }
  }, []);

  const resume = useCallback(() => {
    if (synthRef.current && synthRef.current.paused) {
      synthRef.current.resume();
    }
  }, []);

  return {
    isSupported,
    isSpeaking,
    speak,
    stop,
    pause,
    resume,
  };
}
```

### 2. Update page.tsx to Auto-Play Responses
```typescript
// web/app/page.tsx
import { useSpeechSynthesis } from "@/hooks/useSpeechSynthesis";

export default function Home() {
  const {
    isSupported: ttsSupported,
    isSpeaking,
    speak,
    stop: stopSpeaking,
  } = useSpeechSynthesis();

  const handleReleaseToTalk = async () => {
    stopListening();
    
    if (!sessionId || !transcript) return;

    try {
      const answer = await apiClient.ask(sessionId, transcript);
      setResponse(answer);
      
      // Auto-play response
      if (ttsSupported && answer) {
        speak(answer);
      }
    } catch (err) {
      // ... error handling
    }
  };

  const handleStopSpeaking = () => {
    stopSpeaking();
  };

  return (
    <main>
      {/* ... */}
      
      {/* Response Card with Stop Button */}
      {response && (
        <Card>
          <CardHeader>
            <div className="flex items-center justify-between">
              <CardTitle className="text-lg">Response</CardTitle>
              {isSpeaking && (
                <Button 
                  variant="outline" 
                  size="sm"
                  onClick={handleStopSpeaking}
                >
                  <VolumeX className="h-4 w-4 mr-2" />
                  Stop Speaking
                </Button>
              )}
            </div>
          </CardHeader>
          <CardContent>
            <div className="flex items-start gap-3">
              {isSpeaking && (
                <Volume2 className="h-5 w-5 text-primary animate-pulse" />
              )}
              <ScrollArea className="h-[200px] w-full rounded-md">
                <p className="text-sm whitespace-pre-wrap">{response}</p>
              </ScrollArea>
            </div>
          </CardContent>
        </Card>
      )}
    </main>
  );
}
```

### 3. Add Visual Feedback Component
```typescript
// web/components/SpeakingIndicator.tsx
import { Volume2 } from "lucide-react";

export function SpeakingIndicator() {
  return (
    <div className="flex items-center gap-2 text-primary">
      <Volume2 className="h-5 w-5 animate-pulse" />
      <span className="text-sm font-medium animate-pulse">
        Speaking...
      </span>
    </div>
  );
}
```

## Test Plan

### Success Criteria

- [ ] useSpeechSynthesis hook correctly detects browser support
- [ ] speak() function initiates text-to-speech
- [ ] isSpeaking state updates correctly during playback
- [ ] Responses auto-play immediately after receiving from backend
- [ ] User can stop speech mid-sentence with stop button
- [ ] Visual indicator shows when speech is active
- [ ] Tap anywhere on response card stops speech (optional enhancement)
- [ ] Works on Chrome, Edge, and iOS Safari
- [ ] Voice selection prefers natural/local voices
- [ ] No audio artifacts or cutoffs

### Manual Testing

1. **Basic Playback**:
   - Ask a question
   - Verify response starts playing automatically
   - Verify visual indicator appears
   - Listen to complete response

2. **Interruption**:
   - Ask a long question
   - Click stop button mid-response
   - Verify speech stops immediately
   - Ask another question
   - Verify new response replaces and plays

3. **Multiple Responses**:
   - Ask several questions quickly
   - Verify only latest response plays
   - Verify previous speech is cancelled

## Verification

```bash
cd /home/sean/workspace/janus/web
pnpm dev

# Manual testing required:
# 1. Open http://localhost:3001 with audio enabled
# 2. Ask a question
# 3. Verify response is read aloud automatically
# 4. Verify "Speaking..." indicator appears
# 5. Click "Stop Speaking" button
# 6. Verify speech stops immediately
# 7. Test with long response (>30 seconds)
# 8. Test voice quality and clarity

# Test on mobile:
# 1. Open on iOS Safari
# 2. Enable autoplay for the site
# 3. Verify TTS works
# 4. Test with phone screen locked (may not work)
```

## Files Modified

### New Files
- `web/hooks/useSpeechSynthesis.ts` - Custom hook for text-to-speech with voice selection, rate/pitch control, and playback state management

### Modified Files
- `web/app/page.tsx` - Integrated speech synthesis hook, added auto-play functionality when responses are received, added visual feedback (speaking indicator icon + stop button in Response card header)

### Notes
- Speech synthesis types are already available via browser's built-in TypeScript definitions, no custom types needed
- Visual feedback component was implemented inline in page.tsx rather than as a separate component for simplicity
- Stop button only appears when speech is active (isSpeaking === true)


